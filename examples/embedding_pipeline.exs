# Embedding Generation Pipeline
# Demonstrates using Altar.AI.Integrations.FlowStone for vector embedding generation
#
# This pipeline:
# 1. Loads documents to embed
# 2. Uses Altar.AI.Integrations.FlowStone.embed_each for batch embedding
# 3. Creates a searchable vector index
#
# Usage:
#   MIX_ENV=dev mix run examples/embedding_pipeline.exs
#
# Requirements:
#   - {:altar_ai, path: "../altar_ai"} in mix.exs
#   - (Optional) AI SDKs if you replace the Mock adapter with a real one

defmodule Examples.EmbeddingPipeline do
  @moduledoc """
  Vector embedding generation pipeline using FlowStone and altar_ai.

  Demonstrates:
  - Using Altar.AI.Integrations.FlowStone.embed_each for batch embeddings
  - Processing document collections
  - Building simple vector search indexes
  - Automatic fallback to pseudo-embeddings when AI unavailable
  """

  alias Altar.AI.Adapters.Mock
  alias Altar.AI.Integrations.FlowStone, as: FlowAI

  def run do
    Application.put_env(:flowstone, :io_managers, %{memory: FlowStone.IO.Memory})

    ensure_oban_stopped()
    ensure_started(FlowStone.Registry, name: :embedding_registry)
    ensure_started(FlowStone.IO.Memory, name: :embedding_io)
    ensure_started(FlowStone.Lineage, name: :embedding_lineage)

    # Initialize AI resource with mock adapter (replace with real adapter in production)
    {:ok, ai_resource} = FlowAI.init(adapter: Mock.new())
    Process.put(:ai_resource, ai_resource)

    FlowStone.register(__MODULE__.Pipeline, registry: :embedding_registry)

    IO.puts("Starting Embedding Generation Pipeline...")
    IO.puts("AI capabilities: #{inspect(FlowAI.capabilities(ai_resource))}")
    IO.puts("Processing document batch: docs_batch_001\n")

    result =
      materialize_with_retry(fn ->
        FlowStone.materialize_all(:vector_index,
          partition: "docs_batch_001",
          registry: :embedding_registry,
          io: [config: %{agent: :embedding_io}],
          lineage_server: :embedding_lineage,
          resource_server: nil
        )
      end)

    maybe_drain_oban()

    case result do
      {:ok, index} ->
        IO.puts("\n=== Vector Index Created ===")
        display_index(index)

        # Demo search
        IO.puts("\n=== Demo Search ===")
        demo_search(index)

      :ok ->
        index =
          FlowStone.IO.load(:vector_index, "docs_batch_001", config: %{agent: :embedding_io})

        IO.puts("\n=== Vector Index Created ===")
        display_index(index)

        # Demo search
        IO.puts("\n=== Demo Search ===")
        demo_search(index)

      {:error, reason} ->
        IO.puts("Pipeline failed: #{inspect(reason)}")
    end
  end

  defp display_index(%{document_count: count, embedding_dim: dim, metadata: meta}) do
    IO.puts("Documents indexed: #{count}")
    IO.puts("Embedding dimensions: #{dim}")
    IO.puts("Generated by: #{meta.generator}")
    IO.puts("Created at: #{meta.created_at}")
  end

  defp display_index(index), do: IO.inspect(index, pretty: true)

  defp demo_search(%{documents: documents}) do
    query = "functional programming patterns"
    IO.puts("Query: \"#{query}\"")
    IO.puts("\nTop 3 similar documents:")

    # In production, would use actual vector similarity
    # Here we do simple keyword matching as demo
    results =
      documents
      |> Enum.map(fn doc ->
        score = keyword_similarity(query, doc.content)
        {doc, score}
      end)
      |> Enum.sort_by(fn {_, score} -> -score end)
      |> Enum.take(3)

    Enum.each(results, fn {doc, score} ->
      IO.puts("  - [#{Float.round(score, 2)}] #{String.slice(doc.content, 0, 60)}...")
    end)
  end

  defp demo_search(_), do: IO.puts("No search available")

  defp keyword_similarity(query, content) do
    query_words = query |> String.downcase() |> String.split(~r/\s+/)
    content_lower = String.downcase(content)

    matches = Enum.count(query_words, &String.contains?(content_lower, &1))
    matches / max(length(query_words), 1)
  end

  defp ensure_started(mod, opts) do
    case Process.whereis(opts[:name]) do
      nil -> mod.start_link(opts)
      pid when is_pid(pid) -> {:ok, pid}
    end
  end

  defp maybe_drain_oban do
    if Process.whereis(Oban) do
      FlowStone.ObanHelpers.drain()
    else
      :ok
    end
  end

  defp materialize_with_retry(fun, attempts \\ 3)

  defp materialize_with_retry(fun, attempts) when attempts > 0 do
    case fun.() do
      {:snooze, _delay} ->
        Process.sleep(50)
        materialize_with_retry(fun, attempts - 1)

      other ->
        other
    end
  end

  defp materialize_with_retry(_fun, 0), do: {:error, :snoozed}

  defp ensure_oban_stopped do
    if Process.whereis(Oban.Registry) || Process.whereis(Oban.Config) do
      _ = Application.stop(:oban)

      Enum.each([Oban.Registry, Oban.Config], fn name ->
        case Process.whereis(name) do
          nil -> :ok
          pid -> Process.exit(pid, :kill)
        end
      end)
    end
  end

  defmodule Pipeline do
    @moduledoc """
    Asset definitions for the embedding generation pipeline.
    Uses Altar.AI.Integrations.FlowStone for batch embedding.
    """
    use FlowStone.Pipeline
    alias Altar.AI.Integrations.FlowStone, as: FlowAI

    def sample_documents do
      [
        %{
          id: "doc_001",
          content:
            "Elixir is a dynamic, functional language designed for building scalable and maintainable applications.",
          metadata: %{source: "intro", category: "language"}
        },
        %{
          id: "doc_002",
          content:
            "Pattern matching in Elixir allows you to destructure data and bind variables in a single operation.",
          metadata: %{source: "tutorial", category: "syntax"}
        },
        %{
          id: "doc_003",
          content:
            "GenServer is a behavior module for implementing server processes with state management and supervision.",
          metadata: %{source: "otp", category: "concurrency"}
        },
        %{
          id: "doc_004",
          content:
            "The pipe operator |> chains function calls by passing the result as the first argument to the next function.",
          metadata: %{source: "tutorial", category: "syntax"}
        },
        %{
          id: "doc_005",
          content:
            "Phoenix LiveView enables rich, real-time user experiences with server-rendered HTML and WebSocket connections.",
          metadata: %{source: "web", category: "framework"}
        },
        %{
          id: "doc_006",
          content:
            "Ecto provides a database wrapper and query language for Elixir with support for migrations and changesets.",
          metadata: %{source: "database", category: "framework"}
        },
        %{
          id: "doc_007",
          content:
            "Supervision trees restart failed processes automatically, providing fault tolerance in Elixir applications.",
          metadata: %{source: "otp", category: "reliability"}
        },
        %{
          id: "doc_008",
          content:
            "Macros in Elixir allow compile-time metaprogramming to extend the language and reduce boilerplate code.",
          metadata: %{source: "advanced", category: "metaprogramming"}
        }
      ]
    end

    asset :raw_documents do
      description("Raw documents to embed")

      execute(fn _context, _deps ->
        # In production, would load from database or file system
        {:ok, __MODULE__.sample_documents()}
      end)
    end

    asset :preprocessed_documents do
      description("Documents preprocessed for embedding")
      depends_on([:raw_documents])

      execute(fn _context, %{raw_documents: docs} ->
        preprocessed =
          Enum.map(docs, fn doc ->
            %{
              id: doc.id,
              content: doc.content,
              # Combine content with metadata for richer embeddings
              text_for_embedding: __MODULE__.build_embedding_text(doc),
              metadata: doc.metadata
            }
          end)

        {:ok, preprocessed}
      end)
    end

    asset :embeddings do
      description("Vector embeddings generated via altar_ai")
      depends_on([:preprocessed_documents])

      execute(fn _context, %{preprocessed_documents: docs} ->
        ai = Process.get(:ai_resource)
        __MODULE__.generate_embeddings(ai, docs)
      end)
    end

    asset :vector_index do
      description("Searchable vector index")
      depends_on([:preprocessed_documents, :embeddings])

      execute(fn _context, %{preprocessed_documents: docs, embeddings: embeddings} ->
        __MODULE__.build_index(docs, embeddings)
      end)
    end

    def build_embedding_text(doc) do
      category = doc.metadata[:category] || ""
      "#{category}: #{doc.content}"
    end

    # Embedding generation using Altar.AI.Integrations.FlowStone
    def generate_embeddings(ai, docs) do
      # Use Altar.AI.Integrations.FlowStone.embed_each for batch embedding
      case FlowAI.embed_each(ai, docs, & &1.text_for_embedding) do
        {:ok, embedded_docs} ->
          # Extract embedding dimension from first doc
          dim = get_embedding_dim(embedded_docs)

          {:ok,
           %{
             documents: embedded_docs,
             embedding_dim: dim,
             generator: :altar_ai
           }}

        {:error, _reason} ->
          # Fallback to pseudo-embeddings
          {:ok, generate_fallback_embeddings(docs)}
      end
    end

    defp get_embedding_dim([%{embedding: emb} | _]) when is_list(emb), do: length(emb)
    defp get_embedding_dim(_), do: 256

    defp generate_fallback_embeddings(docs) do
      embedded_docs =
        Enum.map(docs, fn doc ->
          %{
            id: doc.id,
            content: doc.content,
            embedding: text_to_pseudo_embedding(doc.text_for_embedding),
            metadata: doc.metadata
          }
        end)

      %{
        documents: embedded_docs,
        embedding_dim: 256,
        generator: :fallback
      }
    end

    # Simple pseudo-embedding based on character frequencies
    defp text_to_pseudo_embedding(text) do
      # Create a deterministic pseudo-embedding from text
      chars = String.to_charlist(text)

      # Compute character frequency distribution
      freq = Enum.frequencies(chars)

      # Generate 256-dim vector based on character patterns
      0..255
      |> Enum.map(fn i ->
        # Use character position and frequency for pseudo-randomness
        seed = rem(i, 128)
        base = Map.get(freq, seed, 0) / max(length(chars), 1)

        # Add some variation based on text hash
        hash_val = :erlang.phash2({text, i}, 1000) / 1000
        (base + hash_val) / 2
      end)
      |> normalize_vector()
    end

    defp normalize_vector(vector) do
      magnitude = :math.sqrt(Enum.reduce(vector, 0, fn v, acc -> acc + v * v end))

      if magnitude > 0 do
        Enum.map(vector, &(&1 / magnitude))
      else
        vector
      end
    end

    # Index building
    def build_index(_docs, embeddings) do
      # Create document lookup for search
      doc_map =
        Enum.map(embeddings.documents, fn doc ->
          %{
            id: doc.id,
            content: doc.content,
            embedding: doc.embedding,
            metadata: doc.metadata
          }
        end)

      {:ok,
       %{
         documents: doc_map,
         document_count: length(doc_map),
         embedding_dim: embeddings.embedding_dim,
         metadata: %{
           generator: embeddings.generator,
           created_at: DateTime.utc_now()
         }
       }}
    end
  end

  # Vector search utilities
  defmodule VectorSearch do
    @moduledoc """
    Simple vector similarity search.
    """

    def cosine_similarity(vec1, vec2) when length(vec1) == length(vec2) do
      dot_product =
        vec1
        |> Enum.zip(vec2)
        |> Enum.reduce(0, fn {a, b}, acc -> acc + a * b end)

      mag1 = :math.sqrt(Enum.reduce(vec1, 0, fn v, acc -> acc + v * v end))
      mag2 = :math.sqrt(Enum.reduce(vec2, 0, fn v, acc -> acc + v * v end))

      if mag1 > 0 and mag2 > 0 do
        dot_product / (mag1 * mag2)
      else
        0.0
      end
    end

    def cosine_similarity(_, _), do: 0.0

    def search(index, query_embedding, k \\ 5) do
      index.documents
      |> Enum.map(fn doc ->
        similarity = cosine_similarity(query_embedding, doc.embedding)
        {doc, similarity}
      end)
      |> Enum.sort_by(fn {_, sim} -> -sim end)
      |> Enum.take(k)
    end
  end
end

# Run the example
Examples.EmbeddingPipeline.run()
